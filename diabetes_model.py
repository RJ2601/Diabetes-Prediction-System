# -*- coding: utf-8 -*-
"""Diabetes_model (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15L82mCGrX3BA_nDFJ-AnC6qwpp9W3vad
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

df=pd.read_csv('diabetes.csv')
df.head()
df.shape

#lets describe the data
df.describe()

#infromation of dataset
df.info()

#any null values
#not neccessary in above information we can see
df.isnull().values.any()

#histogram
df.hist(bins=10,figsize=(10,10))
plt.show()

#correlation

sns.heatmap(df.corr())
# we can see skin thickness,insulin,pregnencies and age are full independent to each other
#age and pregencies has negative correlation

#lets count total outcome in each target 0 1
#0 means no diabeted
#1 means patient with diabtes
sns.countplot(y=df['Outcome'],palette='Set1')

#box plot
sns.set(style="whitegrid")

sns.set(rc={'figure.figsize':(4,2)})
sns.boxplot(x=df['Insulin'])
plt.show()
sns.boxplot(x=df['BloodPressure'])
plt.show()
sns.boxplot(x=df['DiabetesPedigreeFunction'])
plt.show()

#outlier remove

Q1=df.quantile(0.25)
Q3=df.quantile(0.75)
IQR=Q3-Q1

print("---Q1--- \n",Q1)
print("\n---Q3--- \n",Q3)
print("\n---IQR---\n",IQR)

#print((df < (Q1 - 1.5 * IQR))|(df > (Q3 + 1.5 * IQR)))

#outlier remove
df_out = df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]
df.shape,df_out.shape
#more than 80 records deleted

#lets extract features and targets
X=df_out.drop(columns=['Outcome'])
y=df_out['Outcome']

#Splitting train test data 80 20 ratio
from sklearn.model_selection import train_test_split
train_X,test_X,train_y,test_y=train_test_split(X,y,test_size=0.2)

train_X.shape,test_X.shape,train_y.shape,test_y.shape

from sklearn.metrics import confusion_matrix,accuracy_score,make_scorer
from sklearn.model_selection import cross_validate

def tn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 0]
def fp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 1]
def fn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 0]
def tp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 1]

#cross validation purpose
scoring = {'accuracy': make_scorer(accuracy_score),'prec': 'precision'}
scoring = {'tp': make_scorer(tp), 'tn': make_scorer(tn),
           'fp': make_scorer(fp), 'fn': make_scorer(fn)}

def display_result(result):
    print("TP: ",result['test_tp'])
    print("TN: ",result['test_tn'])
    print("FN: ",result['test_fn'])
    print("FP: ",result['test_fp'])

# Import necessary libraries
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score
from sklearn.model_selection import cross_validate
from sklearn.preprocessing import StandardScaler

# Initialize lists to store accuracy and ROC_AUC values
acc = []
roc = []

# Scale the data
scaler = StandardScaler()
train_X_scaled = scaler.fit_transform(train_X)
test_X_scaled = scaler.transform(test_X)

# Create and train a Logistic Regression model with increased max_iter
clf = LogisticRegression(max_iter=1000)
clf.fit(train_X_scaled, train_y)

# Predict on the test set
y_pred = clf.predict(test_X_scaled)

# Find accuracy
ac = accuracy_score(test_y, y_pred)
acc.append(ac)

# Find the ROC_AUC score
rc = roc_auc_score(test_y, y_pred)
roc.append(rc)
print("\nAccuracy {0} ROC {1}".format(ac, rc))

# Calculate precision and recall after predicting y_pred
precision = precision_score(test_y, y_pred)
recall = recall_score(test_y, y_pred)
print("Precision: {0} Recall: {1}".format(precision, recall))

# Perform cross-validation
result = cross_validate(clf, train_X_scaled, train_y, scoring=scoring, cv=4)
display_result(result)

# Display predicted values (uncomment the line below)
# pd.DataFrame(data={'Actual': test_y, 'Predicted': y_pred}).head()

#Support Vector Machine
from sklearn.svm import SVC
from sklearn.metrics import precision_score, recall_score
clf=SVC(kernel='linear')
clf.fit(train_X,train_y)
y_pred=clf.predict(test_X)
#find accuracy
ac=accuracy_score(test_y,y_pred)
precision = precision_score(test_y, y_pred)
recall = recall_score(test_y, y_pred)

#find the ROC_AOC curve
rc=roc_auc_score(test_y,y_pred)
roc.append(rc)
acc.append(ac)
print("\nAccuracy {0} ROC {1}".format(ac,rc))
print("Precision: {0} Recall: {1}".format(precision, recall))

#cross val score
result=cross_validate(clf,train_X,train_y,scoring=scoring,cv=4)
display_result(result)

#display predicted values uncomment below line
#pd.DataFrame(data={'Actual':test_y,'Predicted':y_pred}).head()

#Random forest
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, roc_auc_score
from sklearn.metrics import precision_score, recall_score

clf=RandomForestClassifier()
clf.fit(train_X,train_y)

y_pred=clf.predict(test_X)
#find accuracy

ac=accuracy_score(test_y,y_pred)
acc.append(ac)
precision = precision_score(test_y, y_pred)
recall = recall_score(test_y, y_pred)


#find the ROC_AOC curve
rc=roc_auc_score(test_y,y_pred)
roc.append(rc)
print("\nAccuracy {0} ROC {1}".format(ac,rc))
print("Precision: {0} Recall: {1}".format(precision, recall))

#cross val score
result=cross_validate(clf,train_X,train_y,scoring=scoring,cv=10)
display_result(result)

#display predicted values uncomment below line
#pd.DataFrame(data={'Actual':test_y,'Predicted':y_pred}).head()

#Gradient Boosting Classifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, roc_auc_score
from sklearn.metrics import precision_score, recall_score

clf=GradientBoostingClassifier(n_estimators=50,learning_rate=0.2)
clf.fit(train_X,train_y)
y_pred=clf.predict(test_X)
#find accuracy
precision = precision_score(test_y, y_pred)
recall = recall_score(test_y, y_pred)
ac=accuracy_score(test_y,y_pred)
acc.append(ac)

#find the ROC_AOC curve
rc=roc_auc_score(test_y,y_pred)
roc.append(rc)
print("\nAccuracy {0} ROC {1}".format(ac,rc))
print("Precision: {0} Recall: {1}".format(precision, recall))

#cross val score
result=cross_validate(clf,train_X,train_y,scoring=scoring,cv=10)
display_result(result)

#display predicted values uncomment below line
#pd.DataFrame(data={'Actual':test_y,'Predicted':y_pred}).head()

input_data = (2	,138,	62,	35	,0	,33.6	,0.127,	47	)
# changing the input_data to numpy array
input_data_as_numpy_array = np.asarray(input_data)

# reshape the array as we are predicting for one instance
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

# standardize the input data
#std_data = scaler.transform(input_data_reshaped)
#print(std_data)

prediction = clf.predict(input_data_reshaped)
print(prediction)

if (prediction[0] == 0):
  print('The person is not diabetic')
else:
  print('The person is diabetic')